{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 설정\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier # 결정트리\n",
    "from sklearn.neighbors import KNeighborsClassifier # k-최근점 이웃\n",
    "from sklearn.linear_model import LogisticRegression # 로지스틱 회귀 모델\n",
    "from sklearn.ensemble import VotingClassifier # 과반수 투표(Majority Voting) \n",
    "from sklearn.ensemble import RandomForestClassifier # 랜덤포레스트\n",
    "from sklearn.ensemble import AdaBoostClassifier # ada부스팅\n",
    "\n",
    "## 모델검정\n",
    "from sklearn.metrics import confusion_matrix, classification_report # 정오분류표\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score # 정확도, 민감도 등\n",
    "from sklearn.metrics import roc_curve, auc # ROC 곡선 그리기\n",
    "\n",
    "## 최적화\n",
    "from sklearn.model_selection import learning_curve, validation_curve # 학습곡선, 검증곡선\n",
    "from sklearn.model_selection import GridSearchCV # 하이퍼파라미터 튜닝\n",
    "from sklearn.model_selection import cross_val_score # 교차타당도 # 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['diagnosis'].unique()\n",
    "def func1(row):\n",
    "    if 'M' in row:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "    \n",
    "df1['판정'] = df1['diagnosis'].apply(func1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df1.drop(columns=['id','diagnosis','Unnamed: 32'])\n",
    "total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. train / test 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = total.drop(['판정'],axis=1)\n",
    "y = total['판정']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=1234, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 구축 및 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting 기법\n",
    "logistic = LogisticRegression(solver='liblinear', penalty='l2', C=0.001, random_state=1)\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=None, criterion='entropy', random_state=1)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, p=2, metric='minkowski')\n",
    "\n",
    "voting_estimators = [('logistic', logistic), ('tree', tree), ('knn', knn)]\n",
    "\n",
    "voting = VotingClassifier(estimators = voting_estimators, voting='soft')\n",
    "\n",
    "clf_labels = ['Logistic regression', 'Decision tree', 'KNN', 'Majority voting']\n",
    "\n",
    "all_clf = [logistic, tree, knn, voting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.3f (+/- %0.3f) [%s]\"\n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['black', 'orange', 'blue', 'green']\n",
    "linestyles = [':', '--', '-.', '-']\n",
    "\n",
    "for clf, label, clr, ls \\\n",
    "        in zip(all_clf, clf_labels, colors, linestyles):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_test,\n",
    "                                     y_score=y_pred)\n",
    "    roc_auc = auc(x=fpr, y=tpr)\n",
    "    plt.plot(fpr, tpr,\n",
    "             color=clr,\n",
    "             linestyle=ls,\n",
    "             label='%s (auc = %0.3f)' % (label, roc_auc))\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1],\n",
    "         linestyle='--',\n",
    "         color='gray',\n",
    "         linewidth=2)\n",
    "\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.grid(alpha=0.5)\n",
    "plt.xlabel('False positive rate (FPR)')\n",
    "plt.ylabel('True positive rate (TPR)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배깅 기법\n",
    "tree = DecisionTreeClassifier(max_depth=None, criterion='entropy', random_state=1)\n",
    "\n",
    "forest = RandomForestClassifier(criterion='gini', n_estimators=500, random_state=1)\n",
    "\n",
    "clf_labels = ['Decision tree', 'Random forest']\n",
    "\n",
    "all_clf = [tree, forest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.3f (+/- %0.3f) [%s]\"\n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['black', 'orange', 'blue', 'green']\n",
    "linestyles = [':', '--', '-.', '-']\n",
    "\n",
    "for clf, label, clr, ls \\\n",
    "        in zip(all_clf, clf_labels, colors, linestyles):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_test,\n",
    "                                     y_score=y_pred)\n",
    "    roc_auc = auc(x=fpr, y=tpr)\n",
    "    plt.plot(fpr, tpr,\n",
    "             color=clr,\n",
    "             linestyle=ls,\n",
    "             label='%s (auc = %0.3f)' % (label, roc_auc))\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1],\n",
    "         linestyle='--',\n",
    "         color='gray',\n",
    "         linewidth=2)\n",
    "\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.grid(alpha=0.5)\n",
    "plt.xlabel('False positive rate (FPR)')\n",
    "plt.ylabel('True positive rate (TPR)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부스팅 기법\n",
    "tree = DecisionTreeClassifier(max_depth=1, criterion='entropy',random_state=1)\n",
    "\n",
    "adaboost = AdaBoostClassifier(base_estimator=tree, n_estimators=500, learning_rate = 0.1, random_state=1)\n",
    "\n",
    "clf_labels = ['Decision tree', 'Ada boost']\n",
    "\n",
    "all_clf = [tree, adaboost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='roc_auc')\n",
    "    print(\"ROC AUC: %0.3f (+/- %0.3f) [%s]\"\n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['black', 'orange', 'blue', 'green']\n",
    "linestyles = [':', '--', '-.', '-']\n",
    "\n",
    "for clf, label, clr, ls \\\n",
    "        in zip(all_clf, clf_labels, colors, linestyles):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_test,\n",
    "                                     y_score=y_pred)\n",
    "    roc_auc = auc(x=fpr, y=tpr)\n",
    "    plt.plot(fpr, tpr,\n",
    "             color=clr,\n",
    "             linestyle=ls,\n",
    "             label='%s (auc = %0.3f)' % (label, roc_auc))\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1],\n",
    "         linestyle='--',\n",
    "         color='gray',\n",
    "         linewidth=2)\n",
    "\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.grid(alpha=0.5)\n",
    "plt.xlabel('False positive rate (FPR)')\n",
    "plt.ylabel('True positive rate (TPR)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 랜덤 포레스트, Adaboost 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_test)\n",
    "print('잘못 분류된 샘플 개수: %d' % (y_test != y_pred).sum())\n",
    "print('정확도: %.3f' % accuracy_score(y_test, y_pred))\n",
    "print('정밀도: %.3f' % precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('재현율: %.3f' % recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "y_pred = adaboost.predict(X_test)\n",
    "\n",
    "print('잘못 분류된 샘플 개수: %d' % (y_test != y_pred).sum())\n",
    "print('정확도: %.3f' % accuracy_score(y_test, y_pred))\n",
    "print('정밀도: %.3f' % precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('재현율: %.3f' % recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('F1: %.3f' % f1_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜덤포레스트 피처 중요도 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_labels = X.columns\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            feat_labels[indices[f]], \n",
    "                            importances[indices[f]]))\n",
    "\n",
    "plt.title('Feature Importance')\n",
    "plt.bar(range(X_train.shape[1]), \n",
    "        importances[indices],\n",
    "        align='center')\n",
    "\n",
    "plt.xticks(range(X_train.shape[1]), \n",
    "           feat_labels[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
